{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6gfvbOX-ZCz"
   },
   "source": [
    "Practical 6\n",
    "\n",
    "Aim : Write a program for implementing L1, L2 regularization, early stopping, dropout with value 0.2.\n",
    "Consider the SONAR dataset. Create a sequential model, with 3 hidden dense layers.\n",
    "Compare the training and testing accuracies of all models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S-hC-5LH-GCi"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras import regularizers, optimizers\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "7XjJDvctDIFd",
    "outputId": "9a1fecdd-9fdb-4e6c-ce7c-a569ae218805"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>Mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>Mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>Mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>Mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>Mine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
       "0         0.0200       0.0371       0.0428       0.0207       0.0954   \n",
       "1         0.0453       0.0523       0.0843       0.0689       0.1183   \n",
       "2         0.0262       0.0582       0.1099       0.1083       0.0974   \n",
       "3         0.0100       0.0171       0.0623       0.0205       0.0205   \n",
       "4         0.0762       0.0666       0.0481       0.0394       0.0590   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "203       0.0187       0.0346       0.0168       0.0177       0.0393   \n",
       "204       0.0323       0.0101       0.0298       0.0564       0.0760   \n",
       "205       0.0522       0.0437       0.0180       0.0292       0.0351   \n",
       "206       0.0303       0.0353       0.0490       0.0608       0.0167   \n",
       "207       0.0260       0.0363       0.0136       0.0272       0.0214   \n",
       "\n",
       "     attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
       "0         0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
       "1         0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
       "2         0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
       "3         0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
       "4         0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
       "..           ...          ...          ...          ...           ...  ...   \n",
       "203       0.1630       0.2028       0.1694       0.2328        0.2684  ...   \n",
       "204       0.0958       0.0990       0.1018       0.1030        0.2154  ...   \n",
       "205       0.1171       0.1257       0.1178       0.1258        0.2529  ...   \n",
       "206       0.1354       0.1465       0.1123       0.1945        0.2354  ...   \n",
       "207       0.0338       0.0655       0.1400       0.1843        0.2354  ...   \n",
       "\n",
       "     attribute_52  attribute_53  attribute_54  attribute_55  attribute_56  \\\n",
       "0          0.0027        0.0065        0.0159        0.0072        0.0167   \n",
       "1          0.0084        0.0089        0.0048        0.0094        0.0191   \n",
       "2          0.0232        0.0166        0.0095        0.0180        0.0244   \n",
       "3          0.0121        0.0036        0.0150        0.0085        0.0073   \n",
       "4          0.0031        0.0054        0.0105        0.0110        0.0015   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "203        0.0116        0.0098        0.0199        0.0033        0.0101   \n",
       "204        0.0061        0.0093        0.0135        0.0063        0.0063   \n",
       "205        0.0160        0.0029        0.0051        0.0062        0.0089   \n",
       "206        0.0086        0.0046        0.0126        0.0036        0.0035   \n",
       "207        0.0146        0.0129        0.0047        0.0039        0.0061   \n",
       "\n",
       "     attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
       "0          0.0180        0.0084        0.0090        0.0032   Rock  \n",
       "1          0.0140        0.0049        0.0052        0.0044   Rock  \n",
       "2          0.0316        0.0164        0.0095        0.0078   Rock  \n",
       "3          0.0050        0.0044        0.0040        0.0117   Rock  \n",
       "4          0.0072        0.0048        0.0107        0.0094   Rock  \n",
       "..            ...           ...           ...           ...    ...  \n",
       "203        0.0065        0.0115        0.0193        0.0157   Mine  \n",
       "204        0.0034        0.0032        0.0062        0.0067   Mine  \n",
       "205        0.0140        0.0138        0.0077        0.0031   Mine  \n",
       "206        0.0034        0.0079        0.0036        0.0048   Mine  \n",
       "207        0.0040        0.0036        0.0061        0.0115   Mine  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"sonar.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdRvbjtCDg3n",
    "outputId": "2664ef6a-5fd1-4318-f34d-146f38e6a55e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.drop(\"Class\", axis = 'columns')\n",
    "data = data.to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzj9nRFvFMwj",
    "outputId": "60c5c3a7-c7af-401a-ad6d-01042d2cb37d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(dataset['Class'])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X5CVHjTOGd3C"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDo5hKAcHGii",
    "outputId": "cfad2135-e962-47de-dd2b-f10b6f6f9457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDfBauQWHqYy",
    "outputId": "9344d42d-54dc-4f96-e0ce-63194bde99e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY0FaXwmNbeq"
   },
   "source": [
    "Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Q3283uCHHlZ",
    "outputId": "87112da2-e63b-451c-a673-d2eeb1cbac84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 92ms/step - loss: 0.6988 - accuracy: 0.4564 - val_loss: 0.6879 - val_accuracy: 0.5882\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6757 - accuracy: 0.5839 - val_loss: 0.6535 - val_accuracy: 0.6471\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6569 - accuracy: 0.6174 - val_loss: 0.6606 - val_accuracy: 0.5882\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6395 - accuracy: 0.6779 - val_loss: 0.6615 - val_accuracy: 0.5882\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6200 - accuracy: 0.7718 - val_loss: 0.6643 - val_accuracy: 0.6471\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5980 - accuracy: 0.7584 - val_loss: 0.6482 - val_accuracy: 0.6471\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5742 - accuracy: 0.7517 - val_loss: 0.6601 - val_accuracy: 0.5882\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5507 - accuracy: 0.7718 - val_loss: 0.6519 - val_accuracy: 0.5882\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5238 - accuracy: 0.7517 - val_loss: 0.6617 - val_accuracy: 0.6471\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4957 - accuracy: 0.7852 - val_loss: 0.6316 - val_accuracy: 0.5882\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4735 - accuracy: 0.7785 - val_loss: 0.6408 - val_accuracy: 0.6471\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4461 - accuracy: 0.8188 - val_loss: 0.6299 - val_accuracy: 0.6471\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4232 - accuracy: 0.8389 - val_loss: 0.6316 - val_accuracy: 0.6471\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4043 - accuracy: 0.8456 - val_loss: 0.6160 - val_accuracy: 0.5882\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3890 - accuracy: 0.8389 - val_loss: 0.6124 - val_accuracy: 0.7059\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3639 - accuracy: 0.8725 - val_loss: 0.6045 - val_accuracy: 0.5882\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3480 - accuracy: 0.8658 - val_loss: 0.6163 - val_accuracy: 0.5882\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3375 - accuracy: 0.8658 - val_loss: 0.6388 - val_accuracy: 0.6471\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3434 - accuracy: 0.8188 - val_loss: 0.6162 - val_accuracy: 0.6471\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3081 - accuracy: 0.9060 - val_loss: 0.6486 - val_accuracy: 0.6471\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2894 - accuracy: 0.9262 - val_loss: 0.5560 - val_accuracy: 0.7059\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2878 - accuracy: 0.8658 - val_loss: 0.5708 - val_accuracy: 0.7059\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.2666 - accuracy: 0.9195 - val_loss: 0.5529 - val_accuracy: 0.7059\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2589 - accuracy: 0.9195 - val_loss: 0.6265 - val_accuracy: 0.6471\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2416 - accuracy: 0.9262 - val_loss: 0.5676 - val_accuracy: 0.7647\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2329 - accuracy: 0.9262 - val_loss: 0.6308 - val_accuracy: 0.7059\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.2167 - accuracy: 0.9262 - val_loss: 0.5810 - val_accuracy: 0.7647\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2172 - accuracy: 0.9329 - val_loss: 0.5877 - val_accuracy: 0.7647\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1923 - accuracy: 0.9329 - val_loss: 0.6815 - val_accuracy: 0.5882\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1988 - accuracy: 0.9262 - val_loss: 0.5597 - val_accuracy: 0.7647\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1851 - accuracy: 0.9262 - val_loss: 0.6198 - val_accuracy: 0.7647\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1680 - accuracy: 0.9597 - val_loss: 0.6003 - val_accuracy: 0.7647\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1569 - accuracy: 0.9463 - val_loss: 0.6357 - val_accuracy: 0.7647\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1517 - accuracy: 0.9597 - val_loss: 0.6504 - val_accuracy: 0.7647\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1417 - accuracy: 0.9664 - val_loss: 0.6661 - val_accuracy: 0.7647\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1405 - accuracy: 0.9664 - val_loss: 0.6063 - val_accuracy: 0.7647\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1224 - accuracy: 0.9732 - val_loss: 0.6898 - val_accuracy: 0.7647\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1174 - accuracy: 0.9732 - val_loss: 0.6832 - val_accuracy: 0.7647\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1052 - accuracy: 0.9799 - val_loss: 0.7198 - val_accuracy: 0.7647\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1021 - accuracy: 0.9799 - val_loss: 0.6687 - val_accuracy: 0.7647\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0959 - accuracy: 0.9866 - val_loss: 0.6824 - val_accuracy: 0.7647\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0902 - accuracy: 0.9866 - val_loss: 0.7334 - val_accuracy: 0.7647\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0860 - accuracy: 0.9866 - val_loss: 0.6793 - val_accuracy: 0.7647\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0898 - accuracy: 0.9732 - val_loss: 0.8235 - val_accuracy: 0.6471\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0849 - accuracy: 0.9799 - val_loss: 0.6650 - val_accuracy: 0.7647\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0742 - accuracy: 0.9933 - val_loss: 0.7717 - val_accuracy: 0.7647\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.7647\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0608 - accuracy: 0.9933 - val_loss: 0.7720 - val_accuracy: 0.7647\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.7647\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.8207 - val_accuracy: 0.7647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc2d8248b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(60,) ))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#fitting the model to training data\n",
    "model.fit(X_train,y_train,epochs = 50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGDO2l4kPM7J",
    "outputId": "08929bdd-e0eb-4a58-9e3b-e1265869a29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "#evaluating training accuracy and loss\n",
    "_, simpleTrainAcc = model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s7xiyJ58Ovfs",
    "outputId": "2178765e-49c5-45c8-ec01-b60d20bebb2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5994 - accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "#evaluating testing accuracy and loss\n",
    "_, simpleTestAcc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MnWUNYBPpQZ"
   },
   "source": [
    "Model with L1 regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQz_p6VePfhC",
    "outputId": "c646976c-6138-472a-c737-d1c60592bd12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 2s 8ms/step - loss: 0.9499 - accuracy: 0.5120\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9033 - accuracy: 0.6265\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8721 - accuracy: 0.6928\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8471 - accuracy: 0.6807\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8135 - accuracy: 0.7169\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7870 - accuracy: 0.7711\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7556 - accuracy: 0.7651\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.7238 - accuracy: 0.7410\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6894 - accuracy: 0.7651\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6636 - accuracy: 0.8072\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6346 - accuracy: 0.7952\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6282 - accuracy: 0.7952\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6156 - accuracy: 0.7771\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5689 - accuracy: 0.8373\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5656 - accuracy: 0.8072\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.8012\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5135 - accuracy: 0.8735\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5114 - accuracy: 0.8373\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.8193\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.8253\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5121 - accuracy: 0.8133\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4652 - accuracy: 0.8675\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.8855\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.8795\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8675\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8855\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8976\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4448 - accuracy: 0.8193\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3816 - accuracy: 0.8976\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3654 - accuracy: 0.8916\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3660 - accuracy: 0.8976\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3392 - accuracy: 0.9277\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.9036\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.9096\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.9277\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.9337\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3135 - accuracy: 0.9277\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.9398\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.9337\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2765 - accuracy: 0.9398\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.9578\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2708 - accuracy: 0.9337\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.9217\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2869 - accuracy: 0.9157\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2660 - accuracy: 0.9398\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2380 - accuracy: 0.9578\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2264 - accuracy: 0.9639\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2203 - accuracy: 0.9578\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2145 - accuracy: 0.9639\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2180 - accuracy: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc298d28b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelL1 = Sequential()\n",
    "modelL1.add(Dense(128, activation='relu', input_shape=(60,) ))\n",
    "modelL1.add(Dense(64, activation='relu'))\n",
    "modelL1.add(Dense(32, activation='relu', kernel_regularizer= regularizers.l1(0.001)))\n",
    "modelL1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#defining optimizer with learning rate\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#compiling the model\n",
    "modelL1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#fitting the model to training data\n",
    "modelL1.fit(X_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cy3x53XsRuRi",
    "outputId": "2fe6dc2d-9ffb-4cff-ee09-7438d7a72c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss and accuracy for L1 regularization\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "print(\"Training loss and accuracy for L1 regularization\")\n",
    "_, L1TrainAcc = modelL1.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogwabpx-So8y",
    "outputId": "5ab760c4-07e7-4f0e-c7f0-ebada4b9284a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss and accuracy for L1 regularization\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3867 - accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing loss and accuracy for L1 regularization\")\n",
    "_, L1TestAcc = modelL1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hvv5MAtqS3-E"
   },
   "source": [
    "L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6_fwU6wSzHS",
    "outputId": "ae7e48ca-fa58-4e71-cf32-93b0676ae0a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 2s 6ms/step - loss: 0.7307 - accuracy: 0.5120\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.7069 - accuracy: 0.6386\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.7229\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.7229\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6518 - accuracy: 0.7410\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.7289\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6096 - accuracy: 0.7831\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.7289\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5740 - accuracy: 0.7410\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5507 - accuracy: 0.7771\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5337 - accuracy: 0.7771\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.8253\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.8072\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.8313\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.8313\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8133\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8072\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.8012\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8133\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8614\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8855\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3491 - accuracy: 0.8855\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8494\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8675\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3074 - accuracy: 0.8916\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2950 - accuracy: 0.9036\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2864 - accuracy: 0.9277\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2722 - accuracy: 0.9277\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2594 - accuracy: 0.9277\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2450 - accuracy: 0.9337\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2361 - accuracy: 0.9458\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2400 - accuracy: 0.9157\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.8976\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2204 - accuracy: 0.9398\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1983 - accuracy: 0.9578\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9578\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1940 - accuracy: 0.9337\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9578\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1893 - accuracy: 0.9337\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1711 - accuracy: 0.9578\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1685 - accuracy: 0.9337\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1464 - accuracy: 0.9639\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1378 - accuracy: 0.9819\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9880\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1437 - accuracy: 0.9759\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9578\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1345 - accuracy: 0.9759\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9880\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.9880\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc2aadb340>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelL2 = Sequential()\n",
    "modelL2.add(Dense(128, activation='relu', input_shape=(60,) ))\n",
    "modelL2.add(Dense(64, activation='relu'))\n",
    "modelL2.add(Dense(32, activation='relu', kernel_regularizer= regularizers.l2(0.001)))\n",
    "modelL2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#defining optimizer with learning rate\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#compiling the model\n",
    "modelL2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#fitting the model to training data\n",
    "modelL2.fit(X_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZTY8u7ITggC",
    "outputId": "27195d15-85f0-4e5e-b495-311cfc5699b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss and accuracy for L2 regularization\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0907 - accuracy: 0.9940\n"
     ]
    }
   ],
   "source": [
    "print(\"Training loss and accuracy for L2 regularization\")\n",
    "_, L2TrainAcc = modelL2.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6CkjJ6JUF_p",
    "outputId": "76698b77-9f07-4c5b-fcec-05bf301d7666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss and accuracy for L2 regularization\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3289 - accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing loss and accuracy for L2 regularization\")\n",
    "_, L2TestAcc = modelL2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OujsDN_kUV1R"
   },
   "source": [
    "Early stopping, patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAZR-IGbUNQh",
    "outputId": "9bcbd448-9aea-47cc-d6dc-176ad8b7c9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 5ms/step - loss: 0.6944 - accuracy: 0.5060\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6637 - accuracy: 0.6446\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.7229\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.7711\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5967 - accuracy: 0.8012\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5680 - accuracy: 0.7711\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.8012\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7952\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.8193\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7711\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7892\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8313\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8072\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8614\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8494\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8193\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8916\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3452 - accuracy: 0.8434\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8735\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8675\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3170 - accuracy: 0.8675\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3007 - accuracy: 0.8855\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.8614\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2778 - accuracy: 0.9096\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2609 - accuracy: 0.8916\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2528 - accuracy: 0.9217\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2813 - accuracy: 0.8614\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8675\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.9096\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2128 - accuracy: 0.9277\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9458\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9398\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1800 - accuracy: 0.9578\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9277\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1662 - accuracy: 0.9458\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9699\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1731 - accuracy: 0.9398\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1528 - accuracy: 0.9398\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1800 - accuracy: 0.9337\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9518\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9578\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9699\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1301 - accuracy: 0.9639\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9699\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0965 - accuracy: 0.9880\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9578\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.9819\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9880\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc2e9ec820>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelES = Sequential()\n",
    "modelES.add(Dense(128, activation='relu', input_shape=(60,) ))\n",
    "modelES.add(Dense(64, activation='relu'))\n",
    "modelES.add(Dense(32, activation='relu'))\n",
    "modelES.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "modelES.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "modelES.fit(X_train, y_train, epochs=50,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_sP9q5xVqs6",
    "outputId": "ba8790dd-fe69-4d04-b30d-d3201a6f1963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss and accuracy for early stopping\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "print(\"Training loss and accuracy for early stopping\")\n",
    "_, ESTrainAcc = modelES.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fGaJ95UWmFk",
    "outputId": "d56d63c1-2817-4b44-d6fa-dab45187323e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss and accuracy for early stopping\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5133 - accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing loss and accuracy for early stopping\")\n",
    "_, ESTestAcc = modelES.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I34zaXRoWzwh"
   },
   "source": [
    "Dropout after input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZmE3DFLWu8j",
    "outputId": "f858c789-fe19-4f07-ebd3-443d4a54e799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 6ms/step - loss: 0.7000 - accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6796 - accuracy: 0.6627\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6698 - accuracy: 0.6386\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.7651\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.6928\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.7349\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.7169\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.7410\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.7229\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7771\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.8133\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5067 - accuracy: 0.8313\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.8253\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7771\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7771\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8012\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8614\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8434\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8434\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8795\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3448 - accuracy: 0.8313\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.8735\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8614\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3009 - accuracy: 0.8916\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8675\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.8193\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3083 - accuracy: 0.8434\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2731 - accuracy: 0.8795\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2385 - accuracy: 0.9096\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.9337\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2151 - accuracy: 0.9458\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2027 - accuracy: 0.9458\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1994 - accuracy: 0.9337\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2040 - accuracy: 0.9157\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2028 - accuracy: 0.9217\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2249 - accuracy: 0.8916\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1635 - accuracy: 0.9819\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1470 - accuracy: 0.9819\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1635 - accuracy: 0.9578\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9699\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9639\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9819\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.9880\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1035 - accuracy: 0.9880\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9759\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9759\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9880\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9759\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9880\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc2fc279d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDO = Sequential()\n",
    "modelDO.add(Dense(128, activation='relu', input_shape=(60,) ))\n",
    "Dropout(0.2)\n",
    "modelDO.add(Dense(64, activation='relu'))\n",
    "modelDO.add(Dense(32, activation='relu'))\n",
    "modelDO.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "modelDO.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "modelDO.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfsdgVhDXb13",
    "outputId": "52e35480-28bb-4073-ec8e-8bbe510adf54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss and accuracy for drop out\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9940\n"
     ]
    }
   ],
   "source": [
    "print(\"Training loss and accuracy for drop out\")\n",
    "_, DOTrainAcc = modelDO.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ON9Tp4wpXtlp",
    "outputId": "b3528ab0-6c0b-4b87-efaa-8b7cbf0b5732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss and accuracy for drop out\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2556 - accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing loss and accuracy for drop out\")\n",
    "_, DOTestAcc = modelDO.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ry3DEnYMYA4I"
   },
   "source": [
    "Comparing the 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "C2Q6Y7ylYDap"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1 regularised</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L2 regularised</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Early stopping (p=5)</td>\n",
       "      <td>0.981928</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dropout (0.2)</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training Accuracy  Testing Accuracy\n",
       "0                Simple           0.963855          0.833333\n",
       "1        L1 regularised           0.963855          0.904762\n",
       "2        L2 regularised           0.993976          0.904762\n",
       "3  Early stopping (p=5)           0.981928          0.809524\n",
       "4         Dropout (0.2)           0.993976          0.857143"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing the values as a dict\n",
    "\n",
    "compareModels = {'Model': ['Simple', 'L1 regularised', 'L2 regularised', 'Early stopping (p=5)', 'Dropout (0.2)'],\n",
    "              'Training Accuracy': [simpleTrainAcc, L1TrainAcc, L2TrainAcc, ESTrainAcc, DOTrainAcc],\n",
    "              'Testing Accuracy': [simpleTestAcc, L1TestAcc, L2TestAcc, ESTestAcc, DOTestAcc]}\n",
    "\n",
    "table = pd.DataFrame(compareModels)\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
